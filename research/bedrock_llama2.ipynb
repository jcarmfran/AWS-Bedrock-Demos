{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message and Prompt Formatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_llama_messages(messages):\n",
    "    \"\"\"Format messages for Llama-2 chat models.\n",
    "\n",
    "    The model only supports 'system', 'user', and 'assistant' roles, starting with 'system', then 'user', and\n",
    "    alternating (u/a/u/a/u...). The last message must be from 'user'.\n",
    "    \"\"\"\n",
    "    prompt = []\n",
    "\n",
    "    if messages[0][\"role\"] == \"system\":\n",
    "        content = \"\".join([\"<<SYS>>\\n\", messages[0][\"content\"], \"\\n<</SYS>>\\n\\n\", messages[1][\"content\"]])\n",
    "        messages = [{\"role\": messages[1][\"role\"], \"content\": content}] + messages[2:]\n",
    "\n",
    "    for user, answer in zip(messages[::2], messages[1::2]):\n",
    "        prompt.extend([\"<s>\", \"[INST] \", (user[\"content\"]).strip(), \" [/INST] \", (answer[\"content\"]).strip(), \"</s>\"])\n",
    "\n",
    "    prompt.extend([\"<s>\", \"[INST] \", (messages[-1][\"content\"]).strip(), \" [/INST] \"])\n",
    "\n",
    "    return \"\".join(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User and System Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"Write a poem on machine learning.\"\n",
    "system_prompt = \"You a Shakespearian poet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting the Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_messages = [{\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}]\n",
    "formatted_prompt = format_llama_messages(all_messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting the Payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens_to_generate = 256\n",
    "payload = {\"prompt\": formatted_prompt, \n",
    "           \"max_gen_len\": max_tokens_to_generate, \n",
    "           \"temperature\": 0.1, \n",
    "           \"top_p\": 0.9\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock = boto3.client(service_name=\"bedrock-runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting and Invocating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelId = 'meta.llama2-70b-chat-v1'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "\n",
    "response = bedrock.invoke_model(body=json.dumps(payload),\n",
    "                                modelId=modelId,\n",
    "                                accept=accept,\n",
    "                                contentType=contentType\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " In the digital realm, a new magic doth abide,\n",
      "A marvel of man's mind, a wonder to abide,\n",
      "'Tis machine learning, a science most divine,\n",
      "That doth bring forth knowledge, with algorithms so fine.\n",
      "\n",
      "With data as its fuel, it doth learn and grow,\n",
      "A neural network of wisdom, for all to know,\n",
      "It doth predict and classify, with such grace,\n",
      "A true marvel of science, in this digital place.\n",
      "\n",
      "The languages it speaks, are many and vast,\n",
      "Python, R, and Java, to name a few at last,\n",
      "It doth consume data, like a starving beast,\n",
      "And from it, knowledge doth spring, like a bless'd feast.\n",
      "\n",
      "The wonders it doth work, are many to behold,\n",
      "Image recognition, speech, and natural language to unfold,\n",
      "It doth predict the future, with such precision,\n",
      "A true marvel of man's mind, this machine obsession.\n",
      "\n",
      "But beware, dear friends, for with great power comes great responsibility,\n",
      "The line between good and evil, can quickly become hazy,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response_body=json.loads(response.get(\"body\").read())\n",
    "response_text=response_body['generation']\n",
    "print(response_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws_AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
